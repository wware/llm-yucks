---
# version: '3.8'
services:
  milvus:
    image: milvusdb/milvus:latest
    ports:
      - "19530:19530"
    volumes:
      - milvus_data:/var/lib/milvus
    environment:
      - TZ=UTC
    networks:
      - ollama-network

  # llm-service:
  #   image: ollama/llm:latest # Replace with the actual image name for your LLM service on Ollama
  #   ports:
  #     - "5000:5000"
  #   environment:
  #     - URL=http://milvus:19530   # URL for the vector DB service

  app:
    build: .
    depends_on:
      ollama:
        condition: service_healthy
    volumes:
      - ./cache:/root/.cache:rw
      - .:/work:rw
      - /home/wware/workdir/static-scanner-qa/worker_python3/saf/saf_job.py:/mycode.py
    environment:
      FETCH: /reference_doc.txt
      OLLAMA_HOST: http://ollama:11434  # Use this in your app to connect to Ollama
    networks:
      - ollama-network

  ollama:
    image: ollama/ollama:latest
    # ports:
    #   - 11434:11434
    volumes:
      - $HOME/.ollama:/root/.ollama:rw
    healthcheck:
      test: bash -c "exec 6<> /dev/tcp/localhost/11434"
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      - URL=http://milvus:19530   # URL for the vector DB service
    networks:
      - ollama-network

  data-ingestion:
    build: ./data-ingestion
    depends_on:
      - milvus
    networks:
      - ollama-network

volumes:
  milvus_data:

networks:
  ollama-network:
    driver: bridge
